### 基础

* [基础知识](docs/basic.md)

* [常见问题](docs/fq.md)

### 经典书目([`百度云`](https://pan.baidu.com/s/1sE_20nHCfej6f9yRaisz7Q) 提取码：b5qq)

* Deep Learning.深度学习必读. [`原书地址`](https://www.deeplearningbook.org/)
* 斯坦福大学《语音与语言处理》第三版：NLP必读. [`原书地址`](http://web.stanford.edu/~jurafsky/slp3/ed3book.pdf)
* Neural Networks and Deep Learning. 入门必读. [`原书地址`](http://neuralnetworksanddeeplearning.com/)
* 复旦大学《神经网络与深度学习》邱锡鹏教授. [`原书地址`](https://nndl.github.io/)
* CS224d: Deep Learning for Natural Language Processing. [`课件地址`](http://cs224d.stanford.edu/)

### 已读论文

* EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks.[`论文`](https://arxiv.org/pdf/1901.11196.pdf)
* Transformer. [`论文`](https://arxiv.org/pdf/1706.03762.pdf)
* Transformer-XL. [`论文`](https://arxiv.org/pdf/1901.02860.pdf)
* Convolutional Neural Networks for Sentence Classification. [`论文`](https://arxiv.org/pdf/1408.5882.pdf)
* Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification. [`论文`](http://www.aclweb.org/anthology/P16-2034)
* A Question-Focused Multi-Factor Attention Network for Question Answering. [`论文`](https://arxiv.org/pdf/1801.08290.pdf)
* AutoCross: Automatic Feature Crossing for Tabular Data in Real-World Applications. [`论文`](https://arxiv.org/pdf/1904.12857.pdf)

### 已读博文

* Transformer.[`博文`](https://jalammar.github.io/illustrated-transformer/)
* Attention-based-model. [`博文`](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/)
* KL divergence. [`博文`](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)
* Building Autoencoders in Keras. [`博文`](https://blog.keras.io/building-autoencoders-in-keras.html)
* Modern Deep Learning Techniques Applied to Natural Language Processing. [`博文`](https://nlpoverview.com/)
* Node2vec embeddings for graph data. [`博文`](https://towardsdatascience.com/node2vec-embeddings-for-graph-data-32a866340fef)
* Bert解读. [`博文`](https://www.cnblogs.com/rucwxb/p/10277217.html)

### 待读论文

* GloVe: Global Vectors for Word Representation. [`官网`](https://nlp.stanford.edu/projects/glove/)
* A Deep Ensemble Model with Slot Alignment for Sequence-to-Sequence Natural Language Generation. [`论文`](https://arxiv.org/pdf/1805.06553.pdf)
* The Design and Implementation of XiaoIce, an Empathetic Social Chatbot. [`论文`](https://arxiv.org/pdf/1812.08989.pdf)
* A Knowledge-Grounded Neural Conversation Model. [`论文`](https://arxiv.org/pdf/1702.01932.pdf)
* Neural Generative Question Answering. [`论文`](https://arxiv.org/pdf/1512.01337v1.pdf)
* A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification. [`论文`](https://arxiv.org/pdf/1510.03820.pdf)
* ImageNet Classification with Deep Convolutional Neural Networks. [`论文`](http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf)
* Network In Network. [`论文`](https://arxiv.org/pdf/1312.4400.pdf),[`翻译`](https://www.jianshu.com/p/8a3f9f06bbe3)
* Long Short-term Memory. [`论文`](http://www.bioinf.jku.at/publications/older/2604.pdf)
* Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation. [`论文`](https://arxiv.org/pdf/1406.1078v3.pdf)
* Get To The Point: Summarization with Pointer-Generator Networks. [`论文`](https://arxiv.org/pdf/1704.04368.pdf)
* Generative Adversarial Text to Image Synthesis. [`论文`](https://arxiv.org/pdf/1605.05396.pdf)
* Image-to-Image Translation with Conditional Adversarial Networks. [`论文`](https://arxiv.org/pdf/1611.07004.pdf)
* Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network. [`论文`](https://arxiv.org/pdf/1609.04802.pdf)
* Unsupervised Learning of Visual Structure using Predictive Generative Networks. [`论文`](https://arxiv.org/pdf/1511.06380.pdf)
* Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks. [`论文`](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.723.6492&rep=rep1&type=pdf)
* Event Extraction via Dynamic Multi-Pooling Convolutional Neural. [`论文`](https://pdfs.semanticscholar.org/ca70/480f908ec60438e91a914c1075b9954e7834.pdf)
* Low-Memory Neural Network Training:A Technical Report. [`论文`](http://web.stanford.edu/~nims/low_memory_training.pdf)
* Language Models are Unsupervised Multitask Learners. [`论文`](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)
* Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context. [`论文`](https://arxiv.org/pdf/1901.02860.pdf)
* BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. [`论文`](https://arxiv.org/pdf/1810.04805.pdf)
* SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient. [`论文`](https://arxiv.org/pdf/1609.05473.pdf)

### 已实现算法

**构建词向量**

- [x] fasttext(skipgram+cbow)
- [x] gensim(word2vec)

**分类算法**

- [x] svm
- [x] fasttext
- [x] textcnn
- [x] bilstm+attention
- [x] bilstm+cnn
- [ ] rcnn
- [ ] han

**NER**

- [x] bilstm+crf

**文本相似度**

- [x] siamese

### 相关github项目

* keras-gpt-2. [`地址`](https://github.com/CyberZHG/keras-gpt-2)
* textClassifier. [`地址`](https://github.com/jiangxinyang227/textClassifier)
* attention-is-all-you-need-keras. [`地址`](https://github.com/Lsdefine/attention-is-all-you-need-keras)
* BERT_with_keras. [`地址`](https://github.com/miroozyx/BERT_with_keras)
* SeqGAN. [`地址`](https://github.com/tyo-yo/SeqGAN)

### 相关博客

* [莫坠青云志](https://tobiaslee.top/)
* [彗双智能-Keras源码分析](http://wangbn.blogspot.com/)
* [机器之心](https://www.jiqizhixin.com/)
* [colah](https://colah.github.io/)
* [ZHPMATRIX](https://zhpmatrix.github.io/)
* [wildml](http://www.wildml.com/)
* [徐阿衡](http://www.shuang0420.com/)
* [零基础入门深度学习](https://www.zybuluo.com/hanbingtao/note/433855)

### 相关会议

* Association of Computational Linguistics(计算语言学协会). [ACL](https://www.aclweb.org/portal/)
* Empirical Methods in Natural Language Processing. [EMNLP]()
* International Conference on Computational Linguistics. [COLING](https://www.sheffield.ac.uk/dcs/research/groups/nlp/iccl/index#tab00)
* Neural Information Processing Systems(神经信息处理系统会议). [NIPS](https://nips.cc/)
* AAAI Conference on Artificial Intelligence. [AAAI](https://www.aaai.org/)
* International Joint Conferences on AI. [IJCAI](https://www.ijcai.org/)
* International Conference on Machine Learning(国际机器学习大会). [ICML](https://icml.cc/)
