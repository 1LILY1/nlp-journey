### 相关会议

[ACL](https://www.aclweb.org/portal/)

 > The Association for Computational Linguistics, NLP最权威的国际专业学会
 
[NIPS](https://nips.cc/)
 
 > Conference and Workshop on Neural Information Processing Systems, 神经信息处理系统大会, 是一个关于机器学习和计算神经科学的国际会议
 
![nips](images/paper/nips.png)

[CICLing](https://www.cicling.org/2018/)

> International Conference on Intelligent Text Processing and Computational Linguistics

[PACLIC](http://www.cbs.polyu.edu.hk/2018paclic/)
 
> Pacific Asia Conference on Language, Information, and Computation

[UAI](http://auai.org/)
 
![AUAI](images/paper/auai.png)
 
[AAAI](https://www.aaai.org/)

![aaai](images/paper/aaai.png)

[IJCAI](https://www.ijcai.org/)

![ijcai](images/paper/ijcai.png)

[ICML](https://icml.cc/)

![icml](images/paper/icml.png)

### 已读论文博客

EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks.[`论文`](https://arxiv.org/pdf/1901.11196.pdf)

> 跟图像一样, 希望采用数据变换的方式来增强文本分类的鲁棒性.\
> 同义词:随机替换, 随机插入, 随机交换位置, 随机删除

Attention-based-model. [`博客`](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/), [`survey`](http://yanran.li/peppypapers/2015/10/07/survey-attention-model-1.html)

![attention](images/attention/attention-based-model.png)

The Illustrated Transformer.[`博客`](https://jalammar.github.io/illustrated-transformer/) [`论文`](https://arxiv.org/pdf/1706.03762.pdf)

* Transformer架构

![transformer](images/transformer.png)

* self-attention细节

###### ![self-attention](images/attention.png)

* encoder细节

![real](images/transformer_resideual_layer_norm_2.png)

Transformer-XL. [`论文`](https://arxiv.org/pdf/1901.02860.pdf)

KL divergence. [`博客`](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)

![kl](images/kl.png)

SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient. [`论文`](https://arxiv.org/pdf/1609.05473.pdf)

Convolutional Neural Networks for Sentence Classification. [`论文`](https://arxiv.org/pdf/1408.5882.pdf)

Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification. [`论文`](http://www.aclweb.org/anthology/P16-2034)

A Question-Focused Multi-Factor Attention Network for Question Answering. [`论文`](https://arxiv.org/pdf/1801.08290.pdf)

![att-mc](images/att-mc.png)

### 待深入

GloVe. [`论文`](https://nlp.stanford.edu/pubs/glove.pdf) [`官网`](https://nlp.stanford.edu/projects/glove/) [`博客`](https://blog.csdn.net/u014665013/article/details/79642083)

A Deep Ensemble Model with Slot Alignment for Sequence-to-Sequence Natural Language Generation. [`论文`](https://arxiv.org/pdf/1805.06553.pdf)

The Design and Implementation of XiaoIce, an Empathetic Social Chatbot. [`论文`](https://arxiv.org/pdf/1812.08989.pdf)

A Knowledge-Grounded Neural Conversation Model. [`论文`](https://arxiv.org/pdf/1702.01932.pdf)

Neural Generative Question Answering. [`论文`](https://arxiv.org/pdf/1512.01337v1.pdf)

A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification. [`论文`](https://arxiv.org/pdf/1510.03820.pdf)

### NLP方面的博客

[莫坠青云志](https://tobiaslee.top/)

[Bert解读](https://www.cnblogs.com/rucwxb/p/10277217.html)

[pytorch-tutorials](https://pytorch.org/tutorials/)

bert分类. [`博客1`](https://www.jiqizhixin.com/articles/2019-03-13-4), [`博客2`](https://www.cnblogs.com/jiangxinyang/p/10241243.html), [`博客3`](https://blog.csdn.net/macanv/article/details/85684284), [`博客4`](http://www.52nlp.cn/bert-paper-%E8%AE%BA%E6%96%87-%E6%96%87%E7%AB%A0-%E4%BB%A3%E7%A0%81%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB)
